{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前工作目录\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 添加项目根目录到 sys.path\n",
    "project_dir = os.path.abspath(os.path.join(current_dir, './'))\n",
    "# print(project_dir)\n",
    "sys.path.append(project_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import editdistance\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# from pylatexenc.latexwalker import LatexWalker, \n",
    "\n",
    "from pylatexenc.latexwalker import LatexWalker\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lns(fpath: str) -> List[str]:\n",
    "    lns = []\n",
    "    with open(fpath, \"r\") as f:\n",
    "        for ln in f.readlines():\n",
    "            lns.append(ln.strip())\n",
    "    return lns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read test caption answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/test/caption.txt\n",
      " max caption size  823\n",
      "7\n",
      "3000 ['0054734', '0037174', '0031510', '0083407', '0037881']\n",
      "['\\\\begin', '{aligned}', '\\\\boldsymbol', '{', 'K', '}', '=', '\\\\left', '(', '\\\\begin', '{array}', '{', 'c', 'c', 'c', '}', '0', '&', '0', '&', '\\\\frac', '{', '\\\\beta', '_', '{', '\\\\mathrm', '{', 'p', '}', '}', '}', '{', '\\\\gamma', '_', '{', '\\\\mathrm', '{', 'm', '}', '}', '}', '\\\\\\\\', '0', '&', '0', '&', '\\\\frac', '{', '\\\\beta', '_', '{', '\\\\mathrm', '{', 'm', '}', '}', '}', '{', '\\\\gamma', '_', '{', '\\\\mathrm', '{', 'm', '}', '}', '}', '\\\\\\\\', '\\\\mathcal', '{', 'P', '}', '\\\\frac', '{', '\\\\beta', '_', '{', '\\\\mathrm', '{', 'f', '}', '}', '}', '{', '\\\\gamma', '_', '{', '\\\\mathrm', '{', 'p', '}', '}', '}', '&', '\\\\frac', '{', '\\\\beta', '_', '{', '\\\\mathrm', '{', 'f', '}', '}', '}', '{', '\\\\gamma', '_', '{', '\\\\mathrm', '{', 'f', '}', '}', '}', '&', '0', '\\\\end', '{array}', '\\\\right', ')', '\\\\end', '{aligned}']\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"../data/test\"\n",
    "test_caption_dir = os.path.join(test_dir,'caption.txt')\n",
    "print(test_caption_dir)\n",
    "caption_dict = {}\n",
    "\n",
    "captions = load_lns(test_caption_dir)\n",
    "max_caption_size = 0\n",
    "count = 0\n",
    "for cap in captions:\n",
    "    img_name = cap.split()[0]\n",
    "    caption_dict[img_name] = cap.split()[1:]\n",
    "    if len(caption_dict[img_name]) > max_caption_size:\n",
    "        max_caption_size = len(caption_dict[img_name])\n",
    "    if len(caption_dict[img_name]) >= 600:\n",
    "        count += 1\n",
    "print(\" max caption size \",max_caption_size)\n",
    "print(count)\n",
    "print(len(caption_dict.keys()),list(caption_dict.keys())[:5])      \n",
    "print(caption_dict[list(caption_dict.keys())[0]])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 78\n",
    "ckp_folder = os.path.join(\"lightning_logs\", f\"version_{version}\", \"checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2993 ['0004028', '0109606', '0035325', '0097565', '0011280']\n",
      "['\\\\begin', '{aligned}', 'm', '_', '{', 'l', '}', '=', '\\\\left', '(', '\\\\begin', '{array}', '{', 'c', 'c', 'c', '}', '0', '.', '0', '0', '2', '5', '6', '&', '-', '0', '.', '0', '1', '0', '5', '8', '&', '0', '\\\\\\\\', '-', '0', '.', '0', '1', '0', '5', '8', '&', '0', '.', '0', '4', '5', '9', '6', '&', '0', '\\\\\\\\', '0', '&', '0', '&', '1', '\\\\end', '{array}', '\\\\right', ')', 'm', '_', '{', '\\\\tau', '}', '\\\\end', '{aligned}']\n"
     ]
    }
   ],
   "source": [
    "pred_dir = '../result'\n",
    "pred_files = os.listdir(pred_dir)\n",
    "pred_dict = {}\n",
    "\n",
    "for pred_file in pred_files:\n",
    "    with open(os.path.join(pred_dir, pred_file), 'r',encoding='utf-8') as f:\n",
    "            latex = f.readlines()[1].strip()\n",
    "            if latex[0] == '$' and latex[-1] == '$':\n",
    "                # replace start and end '$'\n",
    "                latex = latex[1:-1]\n",
    "            pred_dict[pred_file.split(\".\")[0]] = latex.split()\n",
    "        \n",
    "print(len(pred_dict.keys()),list(pred_dict.keys())[:5])\n",
    "\n",
    "print(pred_dict[list(pred_dict.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_edit_distance(seq1, seq2):\n",
    "    \"\"\"计算两个Latex序列之间的编辑距离\"\"\"\n",
    "    return editdistance.eval(seq1, seq2)\n",
    "\n",
    "\n",
    "def calculate_accuracy(pred_dict, true_dict):\n",
    "    \"\"\"计算预测结果与真实结果之间的准确率\"\"\"\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "    for key in pred_dict:\n",
    "        if key in true_dict:\n",
    "            pred_seq = pred_dict[key]\n",
    "            true_seq = true_dict[key]\n",
    "            if pred_seq == true_seq:\n",
    "                correct_count += 1\n",
    "            total_count += 1\n",
    "    return correct_count / total_count if total_count > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_precision_recall_f1(pred_dict, true_dict):\n",
    "    \"\"\"计算精确度、召回率和F1分数\"\"\"\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    all_f1s = []\n",
    "\n",
    "    for key in pred_dict:\n",
    "        if key in true_dict:\n",
    "            pred_seq = pred_dict[key]\n",
    "            true_seq = true_dict[key]\n",
    "            # 转换为二进制分类\n",
    "            true_labels = [1] * len(true_seq)\n",
    "            pred_labels = [1 if i < len(pred_seq) and pred_seq[i] == true_seq[i] else 0 for i in range(len(true_seq))]\n",
    "            if len(pred_labels) < len(true_labels):\n",
    "                pred_labels.extend([0] * (len(true_labels) - len(pred_labels)))\n",
    "            all_precisions.append(precision_score(true_labels, pred_labels))\n",
    "            all_recalls.append(recall_score(true_labels, pred_labels))\n",
    "            all_f1s.append(f1_score(true_labels, pred_labels))\n",
    "\n",
    "    avg_precision = sum(all_precisions) / len(all_precisions) if all_precisions else 0\n",
    "    avg_recall = sum(all_recalls) / len(all_recalls) if all_recalls else 0\n",
    "    avg_f1 = sum(all_f1s) / len(all_f1s) if all_f1s else 0\n",
    "\n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "def is_valid_latex(seq):\n",
    "    \"\"\"检查LaTeX序列是否合法\"\"\"\n",
    "    latex_str = ''.join(seq)\n",
    "    try:\n",
    "        walker = LatexWalker(latex_str)\n",
    "        nodes, pos, len_ = walker.get_latex_nodes()\n",
    "        return True\n",
    "    except ...:\n",
    "        return False\n",
    "\n",
    "def evaluate_by_length_intervals(pred_dict, true_dict, intervals):\n",
    "    \"\"\"按长度区间计算准确率、编辑距离和合法性\"\"\"\n",
    "    interval_results = defaultdict(lambda: {\n",
    "        'correct_count': 0, \n",
    "        'total_count': 0, \n",
    "        'total_edit_distance': 0,\n",
    "        'invalid_count': 0\n",
    "    })\n",
    "\n",
    "    for key in pred_dict:\n",
    "        if key in true_dict:\n",
    "            pred_seq = pred_dict[key]\n",
    "            true_seq = true_dict[key]\n",
    "            length = len(true_seq)\n",
    "            for start, end in intervals:\n",
    "                if start <= length < end:\n",
    "                    interval_results[(start, end)]['total_count'] += 1\n",
    "                    interval_results[(start, end)]['total_edit_distance'] += calculate_edit_distance(pred_seq, true_seq)\n",
    "                    if pred_seq == true_seq:\n",
    "                        interval_results[(start, end)]['correct_count'] += 1\n",
    "                    if not is_valid_latex(pred_seq):\n",
    "                        interval_results[(start, end)]['invalid_count'] += 1\n",
    "                    break\n",
    "\n",
    "    results = {}\n",
    "    for interval, data in interval_results.items():\n",
    "        correct_count = data['correct_count']\n",
    "        total_count = data['total_count']\n",
    "        total_edit_distance = data['total_edit_distance']\n",
    "        invalid_count = data['invalid_count']\n",
    "        accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "        average_edit_distance = total_edit_distance / total_count if total_count > 0 else 0\n",
    "        results[interval] = {\n",
    "            'accuracy': accuracy,\n",
    "            'average_edit_distance': average_edit_distance,\n",
    "            'total_count': total_count,\n",
    "            'invalid_count': invalid_count\n",
    "        }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义长度区间\n",
    "intervals = [(0, 100), (100, 200), (200, 300), (300,400),(400,600),(600,700),(700,800),(800,900),(900,1000)]\n",
    "true_dict = caption_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.46775810223855663\n",
      "Average Precision: 1.0\n",
      "Average Recall: 0.6930390607341295\n",
      "Average F1 Score: 0.7392517982844312\n",
      "Interval Results: {(0, 100): {'accuracy': 0.6376651982378855, 'average_edit_distance': 1.7797356828193833, 'total_count': 908, 'invalid_count': 0}, (100, 200): {'accuracy': 0.4791519434628975, 'average_edit_distance': 4.479151943462898, 'total_count': 1415, 'invalid_count': 0}, (200, 300): {'accuracy': 0.26053639846743293, 'average_edit_distance': 18.09961685823755, 'total_count': 522, 'invalid_count': 0}, (400, 600): {'accuracy': 0.0, 'average_edit_distance': 196.5, 'total_count': 36, 'invalid_count': 0}, (300, 400): {'accuracy': 0.0625, 'average_edit_distance': 53.651785714285715, 'total_count': 112, 'invalid_count': 0}}\n",
      "Interval (0, 100): Accuracy = 0.6376651982378855, Average Edit Distance = 1.7797356828193833, Total Count = 908, Invalid Count = 0\n",
      "Interval (100, 200): Accuracy = 0.4791519434628975, Average Edit Distance = 4.479151943462898, Total Count = 1415, Invalid Count = 0\n",
      "Interval (200, 300): Accuracy = 0.26053639846743293, Average Edit Distance = 18.09961685823755, Total Count = 522, Invalid Count = 0\n",
      "Interval (400, 600): Accuracy = 0.0, Average Edit Distance = 196.5, Total Count = 36, Invalid Count = 0\n",
      "Interval (300, 400): Accuracy = 0.0625, Average Edit Distance = 53.651785714285715, Total Count = 112, Invalid Count = 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 计算整体准确率\n",
    "overall_accuracy = calculate_accuracy(pred_dict, caption_dict)\n",
    "print(f'Overall Accuracy: {overall_accuracy}')\n",
    "\n",
    "# 计算精确度、召回率和F1分数\n",
    "avg_precision, avg_recall, avg_f1 = calculate_precision_recall_f1(pred_dict, true_dict)\n",
    "print(f'Average Precision: {avg_precision}')\n",
    "print(f'Average Recall: {avg_recall}')\n",
    "print(f'Average F1 Score: {avg_f1}')\n",
    "\n",
    "# 计算各长度区间的指标\n",
    "interval_results = evaluate_by_length_intervals(pred_dict, true_dict, intervals)\n",
    "\n",
    "# 调试输出\n",
    "print(f'Interval Results: {interval_results}')\n",
    "\n",
    "for interval, metrics in interval_results.items():\n",
    "    print(f'Interval {interval}: Accuracy = {metrics[\"accuracy\"]}, Average Edit Distance = {metrics[\"average_edit_distance\"]}, Total Count = {metrics[\"total_count\"]}, Invalid Count = {metrics[\"invalid_count\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析模型分析错误的原因，图片分辨率，过长？ 还是。\n",
    "\n",
    "标准化。\n",
    "测其他的指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CoMER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
